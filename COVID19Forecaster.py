# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N53kBHYmbXi_Lu9z-vBrxy8fnmqIE9ry
"""

from keras.models import Sequential
from keras.layers import Dense, LSTM
import math
import numpy as np
from numpy.linalg import pinv
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from typing import Callable
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

# Import data
data = pd.read_csv("https://covid.ourworldindata.org/data/ecdc/total_cases.csv", usecols=["World"])
x = np.arange(0, data.shape[0])
y = data["World"].tolist()

# Predict tomorrow's case number with a long short-term memory neural network
class LSTMNeuralNet:
    def __init__(self, 
                 x: np.ndarray,
                 y: np.ndarray
                 ):
        self.x = x
        self.y = y
        self.prediction = 0
    
    def trainModel(self):
        world_data = data.filter(["World"])
        world_dataset = world_data.values
        training_data_len = len(world_dataset)-1
        scaler = MinMaxScaler(feature_range=(0, 1)) 
        world_scaled_data = scaler.fit_transform(world_dataset)
        train_data = world_scaled_data[0:training_data_len, : ]

        x_train = []
        y_train = []
        for i in range(60,len(train_data)):
            x_train.append(train_data[i-60:i,0])
            y_train.append(train_data[i,0])
  
        x_train, y_train = np.array(x_train), np.array(y_train)
        x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))

        model = Sequential()
        model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
        model.add(LSTM(units=50, return_sequences=False))
        model.add(Dense(units=25))
        model.add(Dense(units=1))
        model.compile(optimizer='adam', loss='mean_squared_error')
        model.fit(x_train, y_train, batch_size=1, epochs=1)

        test_data = world_scaled_data[training_data_len - 60: , : ]
        x_test = []
        y_test = world_dataset[training_data_len : , : ]
        for i in range(60,len(test_data)):
            x_test.append(test_data[i-60:i,0])

        x_test = np.array(x_test)
        x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1],1))

        self.prediction = scaler.inverse_transform(model.predict(x_test))[0][0]

# Fit functions to the data using the Gauss-Newton algorithm
class GaussNewtonAlgo:

    def __init__(self,
                 degree: int,
                 fit_function: Callable,
                 max_iter: int = 1000,
                 tolerance_difference: float = 10 ** (-16),
                 tolerance: float = 10 ** (-9)):
        self.degree = degree
        self.fit_function = fit_function
        self.max_iter = max_iter
        self.tolerance_difference = tolerance_difference
        self.tolerance = tolerance
        self.x = None
        self.y = None
        self.coefficients = None
        self.init_guess = None

    def fit(self,
            x: np.ndarray,
            y: np.ndarray,
            init_guess: np.ndarray) -> np.ndarray:
        self.x = x
        self.y = y
        self.init_guess = init_guess
        self.coefficients = self.init_guess
        rmse_prev = np.inf

        for k in range(self.max_iter):
            residual = self.get_residual()
            jacobian = self._calculate_jacobian(self.coefficients, step=10 ** (-6))
            self.coefficients = self.coefficients - self._calculate_pseudoinverse(jacobian) @ residual
            rmse = np.sqrt(np.sum(residual ** 2))
            diff = np.abs(rmse_prev - rmse)
            if (diff < self.tolerance_difference) or (rmse < self.tolerance):
                return self.coefficients
            rmse_prev = rmse
        
        return self.coefficients

    def predict(self, x: np.ndarray):
        return self.fit_function(self.degree, x, self.coefficients)

    def get_residual(self) -> np.ndarray:
        return self._calculate_residual(self.coefficients)

    def get_estimate(self) -> np.ndarray:
        return self.fit_function(self.degree, self.x, self.coefficients)

    def _calculate_residual(self, coefficients: np.ndarray) -> np.ndarray:
        y_fit = self.fit_function(self.degree, self.x, coefficients)
        return y_fit - self.y

    def _calculate_jacobian(self,
                            x0: np.ndarray,
                            step: float = 10 ** (-6)) -> np.ndarray:
        y0 = self._calculate_residual(x0)

        jacobian = []
        for i, parameter in enumerate(x0):
            x = x0.copy()
            x[i] += step
            y = self._calculate_residual(x)
            derivative = (y - y0) / step
            jacobian.append(derivative)
        jacobian = np.array(jacobian).T

        return jacobian

    @staticmethod
    def _calculate_pseudoinverse(x: np.ndarray) -> np.ndarray:
        return pinv(x.T @ x) @ x.T

# Polynomial function that can be used to fit the data
COEFFICIENTS = [1, 1, 1, 1]
def func(degree, x, coeff):
    returnvar = 0
    for i in range(degree + 1):
        returnvar += coeff[i] * (x ** i)
    return returnvar

solver1 = GaussNewtonAlgo(degree=3, fit_function=func)
init_guess1 = 1000000 * np.random.random(len(COEFFICIENTS))
solver1.fit(x, y, init_guess1)
fit1 = solver1.get_estimate()

solver2 = GaussNewtonAlgo(degree=2, fit_function=func)
init_guess2 = 1000000 * np.random.random(len(COEFFICIENTS))
solver2.fit(x, y, init_guess2)
fit2 = solver2.get_estimate()

lnn = LSTMNeuralNet(x, y)
lnn.trainModel()

plt.figure(figsize=(16,8))
plt.title('Total Number of COVID-19 Cases Worldwide: Current Data and Predicted Data')
plt.xlabel("Time (days)", fontsize=18)
plt.ylabel("Number of Cases", fontsize=18)
plt.plot(x, y, linewidth=4)
xplus20 = np.arange(0, data.shape[0] + 20)
plt.plot(xplus20, func(3, xplus20, solver1.coefficients), linewidth=2)
plt.plot(xplus20, func(2, xplus20, solver2.coefficients), linewidth=2)
plt.legend(['Historical Data', 'Cubic Regression', 'Quadratic Regression'], loc='lower right')
plt.show()

print("There were " + str(y[-2]) + " cases today.")
print("The LSTM neural network predicts that there will be " + str(round(lnn.prediction)) + " cases tomorrow.")
if (lnn.prediction > y[-2]): # increase
  print("This is a " + str(round(100 * ((lnn.prediction / y[-2]) - 1), 3)) + "% increase.")
else: # decrease
  print("This is a " + str(-1 * round(100 * ((lnn.prediction / y[-2]) - 1), 3)) + "% decrease.")